{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e737fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. First 5 rows:\n",
      "    Latitude   Longitude              City  Aggregate rating  \\\n",
      "0  14.565443  121.027535       Makati City               4.8   \n",
      "1  14.553708  121.014101       Makati City               4.5   \n",
      "2  14.581404  121.056831  Mandaluyong City               4.4   \n",
      "3  14.585318  121.056475  Mandaluyong City               4.9   \n",
      "4  14.584450  121.057508  Mandaluyong City               4.8   \n",
      "\n",
      "                           Cuisines  Average Cost for two  \n",
      "0        French, Japanese, Desserts                  1100  \n",
      "1                          Japanese                  1200  \n",
      "2  Seafood, Asian, Filipino, Indian                  4000  \n",
      "3                   Japanese, Sushi                  1500  \n",
      "4                  Japanese, Korean                  1500  \n"
     ]
    }
   ],
   "source": [
    "#LOCATION BASED ANALYSIS\n",
    "#THIS CODE CONTAINS LOADING AND PREPARING THE DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(r'D:\\PardivReddy_Cognifyz\\content\\Dataset .csv')\n",
    "required_cols = ['Latitude', 'Longitude', 'City', 'Aggregate rating', 'Cuisines', 'Average Cost for two']\n",
    "missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns: {missing_cols}. Please ensure Dataset.csv contains these.\")\n",
    "    data = data.dropna(subset=required_cols)\n",
    "else:\n",
    "    data = data[required_cols].dropna()\n",
    "print(\"Data loaded. First 5 rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876d7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (2.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (25.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6724\\1016177348.py:9: DeprecationWarning:\n",
      "\n",
      "*scatter_mapbox* is deprecated! Use *scatter_map* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#VISUAL DISTRIBUTION ON MAP\n",
    "import sys\n",
    "!{sys.executable} -m pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    data,\n",
    "    lat=\"Latitude\",\n",
    "    lon=\"Longitude\",\n",
    "    hover_data=[\"City\", \"Aggregate rating\", \"Cuisines\"],\n",
    "    color=\"Aggregate rating\",\n",
    "    size=\"Average Cost for two\",\n",
    "    zoom=10,\n",
    "    height=600,\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    title=\"Restaurant Distribution by Location\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f8e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Feature  Coefficient\n",
      "0  Average Cost for two     0.000005\n",
      "Progress saved to 'task4_analysis.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def find_col_exists(df, tokens):\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if all(tok in lc for tok in tokens):\n",
    "            return c\n",
    "    return None\n",
    "features = []\n",
    "c1 = find_col_exists(data, ['average','cost'])\n",
    "if c1 is not None:\n",
    "    features.append(c1)\n",
    "c2 = find_col_exists(data, ['votes'])\n",
    "if c2 is not None:\n",
    "    features.append(c2)\n",
    "c3 = find_col_exists(data, ['price','range'])\n",
    "if c3 is not None:\n",
    "    features.append(c3)\n",
    "if not features:\n",
    "    raise KeyError(\"No suitable feature columns found for modeling\")\n",
    "X = data[features].copy()\n",
    "y_col = find_col_exists(data, ['aggregate','rating']) or find_col_exists(data, ['rating'])\n",
    "if y_col is None:\n",
    "    raise KeyError(\"Target column not found\")\n",
    "y = data[y_col].copy()\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col].astype(str).str.replace(',','').str.replace('₹','').str.extract(r'([-+]?\\d*\\.?\\d+)', expand=False), errors='coerce')\n",
    "X = X.fillna(X.median())\n",
    "y = pd.to_numeric(y.astype(str).str.replace(',',''), errors='coerce').fillna(y.mean())\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(coefficients.sort_values(by='Coefficient', ascending=False))\n",
    "with open(str(r'D:\\PardivReddy_Cognifyz\\content\\task4_analysis.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Task 1 Completion Report\\n\")\n",
    "    f.write(f\"Mean Squared Error: {mse}\\n\")\n",
    "    f.write(f\"R-squared Score: {r2}\\n\")\n",
    "    f.write(\"Preprocessed data and model saved locally. Fixed string-to-float error.\\n\")\n",
    "print(\"Progress saved to 'task4_analysis.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec956541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant Concentration by City:\n",
      "                  Restaurant Count  Aggregate rating  Average Cost for two\n",
      "City                                                                      \n",
      "New Delhi                     5473          2.438845            596.088069\n",
      "Gurgaon                       1118          2.651431            714.016100\n",
      "Noida                         1080          2.036204            539.490741\n",
      "Faridabad                      251          1.866932            447.609562\n",
      "Ghaziabad                       25          2.852000            602.000000\n",
      "...                            ...               ...                   ...\n",
      "Trentham East                    1          4.100000             20.000000\n",
      "Weirton                          1          3.900000             25.000000\n",
      "Vineland Station                 1          4.300000             70.000000\n",
      "Winchester Bay                   1          3.200000             25.000000\n",
      "Yorkton                          1          3.300000             25.000000\n",
      "\n",
      "[140 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#GROUP BY CITY AND ANALYZE CONCENTRATION\n",
    "city_stats = data.groupby('City').agg({\n",
    "    'Latitude': 'count',\n",
    "    'Aggregate rating': 'mean',\n",
    "    'Average Cost for two': 'mean'\n",
    "}).rename(columns={'Latitude': 'Restaurant Count'})\n",
    "city_stats = city_stats.sort_values('Restaurant Count', ascending=False)\n",
    "\n",
    "print(\"\\nRestaurant Concentration by City:\")\n",
    "print(city_stats)\n",
    "if 'Locality' in data.columns:\n",
    "    locality_stats = data.groupby('Locality').agg({\n",
    "        'Latitude': 'count',\n",
    "        'Aggregate rating': 'mean',\n",
    "        'Average Cost for two': 'mean'\n",
    "    }).rename(columns={'Latitude': 'Restaurant Count'})\n",
    "    print(\"\\nRestaurant Concentration by Locality (Top 10):\")\n",
    "    print(locality_stats.sort_values('Restaurant Count', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87e4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 City                                          Cuisines  Count\n",
      "0           Abu Dhabi                                          American      2\n",
      "28               Agra                             North Indian, Mughlai      5\n",
      "32          Ahmedabad  Cafe, American, Continental, Armenian, Fast Food      1\n",
      "64             Albany                            Japanese, Steak, Sushi      2\n",
      "78          Allahabad                             North Indian, Chinese      3\n",
      "...               ...                                               ...    ...\n",
      "2993          Weirton                           Burger, Greek, Sandwich      1\n",
      "2996  Wellington City                                              Cafe      3\n",
      "3011   Winchester Bay                            Burger, Seafood, Steak      1\n",
      "3012          Yorkton                                             Asian      1\n",
      "3015        ��stanbul                                              Cafe      3\n",
      "\n",
      "[140 rows x 3 columns]\n",
      "- High concentration of restaurants in a few cities.\n",
      "- Significant variation in average ratings across cities.\n",
      "Analysis saved to 'task4_analysis.txt'.\n"
     ]
    }
   ],
   "source": [
    "#CALCULATE STATICTICS AND INSIGHTS\n",
    "cuisine_counts = data.groupby(['City', 'Cuisines']).size().reset_index(name='Count')\n",
    "top_cuisines = cuisine_counts.loc[cuisine_counts.groupby('City')['Count'].idxmax()]\n",
    "print(top_cuisines)\n",
    "insights = []\n",
    "if city_stats['Restaurant Count'].max() > city_stats['Restaurant Count'].median() * 2:\n",
    "    insights.append(\"High concentration of restaurants in a few cities.\")\n",
    "if city_stats['Aggregate rating'].std() > 0.5:\n",
    "    insights.append(\"Significant variation in average ratings across cities.\")\n",
    "if data['Average Cost for two'].corr(data['Aggregate rating']) > 0.3:\n",
    "    insights.append(\"Positive correlation between cost and rating.\")\n",
    "for insight in insights:\n",
    "    print(\"-\", insight)\n",
    "with open(str(r'D:\\PardivReddy_Cognifyz\\content\\task4_analysis.txt'), 'w', encoding='utf-8') as f:\n",
    "    from datetime import date\n",
    "    f.write(f\"Task 4: Location-based Analysis Report - {date.today().isoformat()}\\n\")\n",
    "    f.write(\"Restaurant Concentration by City:\\n\")\n",
    "    f.write(city_stats.to_string() + \"\\n\")\n",
    "    f.write(\"Most Common Cuisine by City:\\n\")\n",
    "    f.write(top_cuisines.to_string() + \"\\n\")\n",
    "    f.write(\"Insights:\\n\")\n",
    "    f.write(\"\\n\".join(insights) + \"\\n\")\n",
    "print(\"Analysis saved to 'task4_analysis.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c84a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
